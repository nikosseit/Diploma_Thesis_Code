This repository contains the code for my diploma thesis, which presents an assistive system developed to help users efficiently locate their last focus point within multi-window environments. Implemented in Python with PostgreSQL integration, the system processes and filters real-time gaze data from an eye-tracking device using a custom-developed algorithm, accurately predicting the user's last point of visual engagement. This project highlights my work in human-computer interaction, focusing on solutions that enhance user experience through live data processing and adaptive focus point identification, meeting the challenges of real-time accuracy in dynamic interface management.

Within the DIPLOMA_CODE file, you will find all necessary components for implementing this system. The **BOX_CLUSTER** file is responsible for creating an indicator at specific screen coordinates; it uses the last recorded focus point as input, displaying the indicator directly on this last engagement location. The **Fixed_Size_Queue** file is a custom queue that maintains only the most recent entries, discarding older data to consistently represent the last focus point. The **MAIN** file contains the core implementation, featuring data filtering functions and database operations that store and retrieve data from a PostgreSQL table, with configuration details provided in **config.json**.

The system was rigorously tested through a use-case scenario (**use_cases_scenario.docx**) involving 68 participants, who experienced and evaluated its functionality. Results indicated that the system significantly reduced task completion times, effectively assisting users by reliably indicating their last focus point in real-time.
